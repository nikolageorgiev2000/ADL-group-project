{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0873814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "\n",
    "# Set up the data directories\n",
    "data_dir = '.data/images'\n",
    "annotation_dir = '.data/annotations'  # Add annotations directory\n",
    "\n",
    "# Get list of image files\n",
    "image_files = sorted([f for f in os.listdir(data_dir) if f.endswith(('.jpg', '.png'))])[:4]\n",
    "\n",
    "# Create a figure with 2x4 subplots (original image + trimap for each row)\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "\n",
    "# Load and display first 4 images with their annotations\n",
    "for idx, img_file in enumerate(image_files):\n",
    "    # Load original image\n",
    "    img_path = os.path.join(data_dir, img_file)\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    # Load trimap segmentation\n",
    "    trimap_file = img_file.replace('.jpg', '.png')\n",
    "    trimap_path = os.path.join(annotation_dir, 'trimaps', trimap_file)\n",
    "    trimap = Image.open(trimap_path)\n",
    "    \n",
    "    # Plot in corresponding subplots\n",
    "    row = idx // 2\n",
    "    col = idx % 2 * 2  # Multiply by 2 to leave space for annotations\n",
    "    \n",
    "    # Plot original image\n",
    "    axes[row, col].imshow(img)\n",
    "    axes[row, col].axis('off')\n",
    "    axes[row, col].set_title(f'{img_file.split(\"_\")[0]} - Original')\n",
    "    \n",
    "    # Plot trimap segmentation\n",
    "    axes[row, col + 1].imshow(trimap, cmap='tab20')\n",
    "    axes[row, col + 1].axis('off')\n",
    "    axes[row, col + 1].set_title('Segmentation Mask')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Display annotation statistics\n",
    "def print_annotation_info():\n",
    "    print(\"\\nDataset Annotations Include:\")\n",
    "    print(\"1. Species/Breed Names (37 categories)\")\n",
    "    print(\"2. Head Bounding Box (ROI)\")\n",
    "    print(\"3. Trimap Segmentation:\")\n",
    "    print(\"   - 1: Pet\")\n",
    "    print(\"   - 2: Background\")\n",
    "    print(\"   - 3: Border/Undefined\")\n",
    "\n",
    "print_annotation_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224fda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dataset and dataloader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class PetSegmentationDataset(Dataset):\n",
    "    def __init__(self, data_dir, annotation_dir, transform):\n",
    "        self.data_dir = data_dir\n",
    "        self.annotation_dir = annotation_dir\n",
    "        self.image_files = [f for f in os.listdir(data_dir) if f.endswith(('.jpg', '.png'))]\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.data_dir, self.image_files[idx])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Load trimap\n",
    "        trimap_file = self.image_files[idx].replace('.jpg', '.png')\n",
    "        trimap_path = os.path.join(self.annotation_dir, 'trimaps', trimap_file)\n",
    "        trimap = Image.open(trimap_path)\n",
    "        \n",
    "        # Apply transforms\n",
    "        img = self.transform(img)\n",
    "        trimap = torch.tensor(np.array(trimap.resize((256, 256))), dtype=torch.long)\n",
    "        \n",
    "        return img, trimap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de57d28c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the segmentation model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleSegNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        \n",
    "        # Decoder\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.upconv2 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
    "        self.final = nn.Conv2d(32, 3, 1)  # 3 classes: pet, background, border\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoding\n",
    "        x1 = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x2 = F.relu(F.max_pool2d(self.conv2(x1), 2))\n",
    "        x3 = F.relu(self.conv3(x2))\n",
    "        \n",
    "        # Decoding\n",
    "        x = F.relu(self.upconv1(x3))\n",
    "        x = F.relu(self.upconv2(x))\n",
    "        return self.final(x)\n",
    "\n",
    "\n",
    "model = SimpleSegNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (images, targets) in enumerate(train_dataloader):\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c30913",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# Visualization function\n",
    "def visualize_predictions(model, dataset, num_samples=4):\n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "    \n",
    "    for idx in range(num_samples):\n",
    "        img, true_mask = dataset[idx]\n",
    "        with torch.no_grad():\n",
    "            pred = model(img.unsqueeze(0).to(device))\n",
    "            pred_mask = torch.argmax(pred, dim=1).squeeze().cpu()\n",
    "        \n",
    "        # Plot original image\n",
    "        axes[idx, 0].imshow(img.permute(1, 2, 0))\n",
    "        axes[idx, 0].set_title('Original Image')\n",
    "        axes[idx, 0].axis('off')\n",
    "        \n",
    "        # Plot true mask\n",
    "        axes[idx, 1].imshow(true_mask, cmap='tab20')\n",
    "        axes[idx, 1].set_title('True Mask')\n",
    "        axes[idx, 1].axis('off')\n",
    "        \n",
    "        # Plot predicted mask\n",
    "        axes[idx, 2].imshow(pred_mask, cmap='tab20')\n",
    "        axes[idx, 2].set_title('Predicted Mask')\n",
    "        axes[idx, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluate_model_metrics(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Evaluate model performance using various classification metrics.\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model to evaluate\n",
    "        dataloader: PyTorch DataLoader containing validation/test data\n",
    "        device: Device to run model on ('cuda' or 'cpu')\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing computed metrics\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import accuracy_score, recall_score, jaccard_score, f1_score\n",
    "    import numpy as np\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds.flatten())\n",
    "            all_targets.extend(targets.numpy().flatten())\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(all_targets, all_preds),\n",
    "        'recall': recall_score(all_targets, all_preds, average='macro'),\n",
    "        'jaccard': jaccard_score(all_targets, all_preds, average='macro'),\n",
    "        'f1': f1_score(all_targets, all_preds, average='macro')\n",
    "    }\n",
    "\n",
    "    print(f\"\\nModel Performance Metrics:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"Jaccard Index: {metrics['jaccard']:.4f}\") \n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde7981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c9cc8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# preprocess_input = get_preprocessing_fn('resnet18', pretrained='imagenet')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
    "    # transforms.Lambda(preprocess_input),\n",
    "])\n",
    "dataset = PetSegmentationDataset(data_dir, annotation_dir, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b166e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, checkpoint_path):\n",
    "    \"\"\"Load model from checkpoint\"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return model, checkpoint['epoch'], checkpoint['best_loss']\n",
    "\n",
    "def train_model(\n",
    "    model,\n",
    "    dataset,\n",
    "    train_samples=128,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    learning_rate=3e-5,\n",
    "    optimizer_name='adam',\n",
    "    scheduler_name='cosine',\n",
    "    checkpoint_dir='checkpoints',\n",
    "    resume_from=None\n",
    "):\n",
    "    \"\"\"Train the segmentation model with checkpointing and scheduling\"\"\"\n",
    "    \n",
    "    # Create train/val split\n",
    "    train_size = train_samples\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Set up optimizer\n",
    "    if optimizer_name.lower() == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer_name.lower() == 'sgd':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n",
    "\n",
    "    # Set up scheduler\n",
    "    if scheduler_name.lower() == 'cosine':\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    elif scheduler_name.lower() == 'reduce_on_plateau':\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported scheduler: {scheduler_name}\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_loss = float('inf')\n",
    "    start_epoch = 0\n",
    "\n",
    "    # Resume from checkpoint if specified\n",
    "    if resume_from:\n",
    "        model, start_epoch, best_loss = load_checkpoint(model, resume_from)\n",
    "        print(f\"Resuming from epoch {start_epoch} with best loss {best_loss:.4f}\")\n",
    "\n",
    "    # Create checkpoint directory\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, targets in train_dataloader:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        # Update scheduler\n",
    "        if scheduler_name.lower() == 'cosine':\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        # Save checkpoint if best loss\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': epoch_loss,\n",
    "                'best_loss': best_loss\n",
    "            }\n",
    "            torch.save(checkpoint, f\"{checkpoint_dir}/best_model.pth\")\n",
    "\n",
    "        # Save periodic checkpoint\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': epoch_loss,\n",
    "                'best_loss': best_loss\n",
    "            }\n",
    "            torch.save(checkpoint, f\"{checkpoint_dir}/checkpoint_epoch_{epoch+1}.pth\")\n",
    "\n",
    "    print(\"\\nTraining complete!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b089899f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "print(\"\\n=== Using Segmentation Models PyTorch (SMP) for improved performance ===\\n\")\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "\n",
    "# Create SMP model - Using UNet with ResNet34 encoder pre-trained on ImageNet\n",
    "smp_model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # Choose encoder, e.g. resnet34\n",
    "    encoder_weights=\"imagenet\",     # Use pre-trained weights\n",
    "    in_channels=3,                  # Number of input channels (RGB)\n",
    "    classes=3,                      # Number of output classes (pet, background, border)\n",
    ").to(device)\n",
    "\n",
    "train_model(smp_model, dataset, train_samples=128, batch_size=64, epochs=100, learning_rate=3e-5, optimizer_name='adam', scheduler_name='cosine', checkpoint_dir='checkpoints', resume_from=None)\n",
    "\n",
    "ckpt_model, ckpt_epoch, ckpt_best_loss = load_checkpoint(smp_model, 'checkpoints/best_model.pth')\n",
    "\n",
    "metrics = visualize_predictions(smp_model, (train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71d49c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
